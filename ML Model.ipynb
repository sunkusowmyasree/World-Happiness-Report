{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model for 2020 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Happiness Rank</th>\n",
       "      <th>Happiness Score</th>\n",
       "      <th>Economy (GDP per Capita)</th>\n",
       "      <th>Family</th>\n",
       "      <th>Health (Life Expectancy)</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Trust (Government Corruption)</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finland</td>\n",
       "      <td>1</td>\n",
       "      <td>7.8087</td>\n",
       "      <td>10.639267</td>\n",
       "      <td>0.954330</td>\n",
       "      <td>71.900825</td>\n",
       "      <td>0.949172</td>\n",
       "      <td>0.195445</td>\n",
       "      <td>-0.059482</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>2</td>\n",
       "      <td>7.6456</td>\n",
       "      <td>10.774001</td>\n",
       "      <td>0.955991</td>\n",
       "      <td>72.402504</td>\n",
       "      <td>0.951444</td>\n",
       "      <td>0.168489</td>\n",
       "      <td>0.066202</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>3</td>\n",
       "      <td>7.5599</td>\n",
       "      <td>10.979933</td>\n",
       "      <td>0.942847</td>\n",
       "      <td>74.102448</td>\n",
       "      <td>0.921337</td>\n",
       "      <td>0.303728</td>\n",
       "      <td>0.105911</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>4</td>\n",
       "      <td>7.5045</td>\n",
       "      <td>10.772559</td>\n",
       "      <td>0.974670</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.948892</td>\n",
       "      <td>0.711710</td>\n",
       "      <td>0.246944</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norway</td>\n",
       "      <td>5</td>\n",
       "      <td>7.4880</td>\n",
       "      <td>11.087804</td>\n",
       "      <td>0.952487</td>\n",
       "      <td>73.200783</td>\n",
       "      <td>0.955750</td>\n",
       "      <td>0.263218</td>\n",
       "      <td>0.134533</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country  Happiness Rank  Happiness Score  Economy (GDP per Capita)  \\\n",
       "0      Finland               1           7.8087                 10.639267   \n",
       "1      Denmark               2           7.6456                 10.774001   \n",
       "2  Switzerland               3           7.5599                 10.979933   \n",
       "3      Iceland               4           7.5045                 10.772559   \n",
       "4       Norway               5           7.4880                 11.087804   \n",
       "\n",
       "     Family  Health (Life Expectancy)   Freedom  \\\n",
       "0  0.954330                 71.900825  0.949172   \n",
       "1  0.955991                 72.402504  0.951444   \n",
       "2  0.942847                 74.102448  0.921337   \n",
       "3  0.974670                 73.000000  0.948892   \n",
       "4  0.952487                 73.200783  0.955750   \n",
       "\n",
       "   Trust (Government Corruption)  Generosity  Year  \n",
       "0                       0.195445   -0.059482  2020  \n",
       "1                       0.168489    0.066202  2020  \n",
       "2                       0.303728    0.105911  2020  \n",
       "3                       0.711710    0.246944  2020  \n",
       "4                       0.263218    0.134533  2020  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To Handle Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "#To make plots and Visualize the Data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "\n",
    "#TO Build a ML Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n",
    "#Read all the Excel Files which have Report Data from 2016 to 2020\n",
    "\n",
    "##########     Reading the 2020 Report ##########################\n",
    "df_2020=pd.read_csv('./2020.csv')\n",
    "\n",
    "#There is no Happiness Rank in the Datset while Remaining Datasets Have. good part is data is ordered as per the Rank\n",
    "df_2020['Happiness Rank'] =  range(1, len(df_2020.index)+1)\n",
    "\n",
    "#Renaming the Columns so that all datasets have similar Header Names which will be Required later to Analyse Data from cumulative Years\n",
    "\n",
    "df_2020 = df_2020.rename(columns = {'Country name' : 'Country', 'Ladder score' : 'Happiness Score', \n",
    "                        'Logged GDP per capita' : 'Economy (GDP per Capita)', 'Social support' : 'Family', \n",
    "                                    'Healthy life expectancy' : 'Health (Life Expectancy)',\n",
    "                        'Freedom to make life choices' : 'Freedom', \n",
    "                                    'Perceptions of corruption' : 'Trust (Government Corruption)'})\n",
    "\n",
    "#Adding Year Column in order to differentiate data easily\n",
    "df_2020['Year']=2020\n",
    "\n",
    "##########     Reading the 2019 Report ##########################\n",
    "df_2019 = pd.read_csv('./2019.csv')\n",
    "df_2019['Year']=2019\n",
    "df_2019 = df_2019.rename(columns = {'Overall rank':'Happiness Rank', 'Country or region' : 'Country', 'Score' : 'Happiness Score',\n",
    "                                      'GDP per capita' : 'Economy (GDP per Capita)', 'Social support' : 'Family',\n",
    "                                      'Healthy life expectancy' : 'Health (Life Expectancy)','Freedom to make life choices' : 'Freedom'\n",
    "                                     , 'Perceptions of corruption' : 'Trust (Government Corruption)'})\n",
    "\n",
    "\n",
    "##########     Reading the 2018 Report ##########################\n",
    "df_2018 = pd.read_csv('./2018.csv')\n",
    "df_2018['Year']=2018\n",
    "df_2018 = df_2018.rename(columns = {'Overall rank':'Happiness Rank', 'Country or region' : 'Country', 'Score' : 'Happiness Score',\n",
    "                                      'GDP per capita' : 'Economy (GDP per Capita)', 'Social support' : 'Family',\n",
    "                                      'Healthy life expectancy' : 'Health (Life Expectancy)',\n",
    "                                      'Freedom to make life choices' : 'Freedom',\n",
    "                                      'Perceptions of corruption' : 'Trust (Government Corruption)'})\n",
    "\n",
    "##########     Reading the 2017 Report ##########################\n",
    "df_2017 = pd.read_csv('./2017.csv')\n",
    "df_2017 = df_2017.rename(columns = {'Happiness.Rank':'Happiness Rank', 'Happiness.Score' : 'Happiness Score', \n",
    "                                      'Economy..GDP.per.Capita.' : 'Economy (GDP per Capita)', 'Health..Life.Expectancy.' : 'Health (Life Expectancy)',\n",
    "                                      'Trust..Government.Corruption.' : 'Trust (Government Corruption)', 'Dystopia.Residual' : 'Dystopia Residual'})\n",
    "df_2017['Year']=2017\n",
    "\n",
    "##########     Reading the 2016 Report ##########################\n",
    "df_2016= pd.read_csv('./2016.csv')\n",
    "df_2016['Year']=2016\n",
    "\n",
    "##########     Reading the 2015 Report ##########################\n",
    "df_2015 = pd.read_csv('./2015.csv')\n",
    "df_2015['Year']=2015\n",
    "\n",
    "##########  Concat all the Years Data into a single dataframe ##########################\n",
    "df_all = pd.concat([df_2020,df_2019,df_2018,df_2017,df_2016,df_2015])\n",
    "\n",
    "df_all=df_all[['Country', 'Happiness Rank', 'Happiness Score', 'Economy (GDP per Capita)',\n",
    "                                   'Family', 'Health (Life Expectancy)', 'Freedom','Trust (Government Corruption)',\n",
    "                                   'Generosity', 'Year']]\n",
    "#Print Top 5 rows from the dataset\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filling Missing Values with Mean of each column**\n",
    "\n",
    "Filling Missing Values with Mean of Each Column. Here Mean Method is choosen because Each row is a country and every country has a different score for each metric so mode can't be choosen. That's why Mean Method will take the Average of the entire column and fill null values with it which is Reasonable Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIll missing Values with Mean\n",
    "df_all.fillna((df_all.mean()), inplace = True)\n",
    "df_2020.fillna((df_2020.mean()), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing Linear Regression Model to Predict Happiness Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lmmodel(df):\n",
    "    '''\n",
    "    INPUT - DataFrame\n",
    "    OUTPUT - Returns \n",
    "    r2 score for Test Dataset \n",
    "    Length of Test Datset\n",
    "    r2 score for Train Dataset\n",
    "    Length of Train Dataset\n",
    "    '''\n",
    "    #Choosing X and Y columns Y- Happiness Score which needs to be Predicted X - Features to Tarin Model\n",
    "    y=df['Happiness Score']\n",
    "    X=df[['Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)','Freedom', 'Generosity',\n",
    "           'Trust (Government Corruption)']]\n",
    "    \n",
    "    #Splitting Test and Train Dataset\n",
    "    X_train,X_test,Y_train,Y_test= train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "    #Initiating Linear Regression Model\n",
    "    lin_reg = LinearRegression()\n",
    "    \n",
    "    #Fit the Model\n",
    "    lin_reg.fit(X_train,Y_train)\n",
    "    \n",
    "    #Predict the Happiness Score for Test and Train Dataset\n",
    "    y_test_preds = lin_reg.predict(X_test)\n",
    "    y_train_preds = lin_reg.predict(X_train)\n",
    "    \n",
    "    #Finding Score, Mean Squared Error and Mean Absolute Error\n",
    "    score=lin_reg.score(X_test, Y_test)\n",
    "    mse = mean_squared_error(Y_test, y_test_preds)\n",
    "    mae = mean_absolute_error(Y_test, y_test_preds)\n",
    "    \n",
    "    #R2 Score for Model\n",
    "    r2_test = r2_score(Y_test, y_test_preds)\n",
    "    r2_train = r2_score(Y_train, y_train_preds) \n",
    "    \n",
    "    #Length of Test and Train Dataset\n",
    "    len_ytest = len(y_test_preds)\n",
    "    len_ytrain = len(y_train_preds)\n",
    "    \n",
    "    return r2_test, len_ytest, r2_train, len_ytrain\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r-squared score for the Test model using only quantitative variables was 0.5822946834680572 on 31 values.\n",
      "The r-squared score for the Test model using only quantitative variables was 0.7652214982201764 on 122 values.\n",
      "The r-squared score for the Train model using only quantitative variables was 0.6596653871355431 on 187 values.\n",
      "The r-squared score for the Train model using only quantitative variables was 0.635648854474053 on 748 values.\n"
     ]
    }
   ],
   "source": [
    "#Predicting Happiness Score for 2020 Dataset by using lmmodel Function\n",
    "r2_test, len_ytest, r2_train,len_ytrain = lmmodel(df_2020)\n",
    "print(\"The r-squared score for the Test model using only quantitative variables was {} on {} values.\".format(r2_test,len_ytest))\n",
    "print(\"The r-squared score for the Test model using only quantitative variables was {} on {} values.\".format(r2_train,len_ytrain))\n",
    "#Predicting Happiness Score for total Dataset by using lmmodel Function\n",
    "\n",
    "r2_test, len_ytest, r2_train,len_ytrain = lmmodel(df_all)\n",
    "print(\"The r-squared score for the Train model using only quantitative variables was {} on {} values.\".format(r2_test,len_ytest))\n",
    "print(\"The r-squared score for the Train model using only quantitative variables was {} on {} values.\".format(r2_train,len_ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_lm_mod(X, y, cutoffs, test_size = .30, random_state=42, plot=True):\n",
    "    '''\n",
    "    INPUT\n",
    "    X - pandas dataframe, X matrix\n",
    "    y - pandas dataframe, response variable\n",
    "    cutoffs - list of ints, cutoff for number of non-zero values in dummy categorical vars\n",
    "    test_size - float between 0 and 1, default 0.3, determines the proportion of data as test data\n",
    "    random_state - int, default 42, controls random state for train_test_split\n",
    "    plot - boolean, default 0.3, True to plot result\n",
    "    OUTPUT\n",
    "    r2_scores_test - list of floats of r2 scores on the test data\n",
    "    r2_scores_train - list of floats of r2 scores on the train data\n",
    "    lm_model - model object from sklearn\n",
    "    X_train, X_test, y_train, y_test - output from sklearn train test split used for optimal model\n",
    "    '''\n",
    "    r2_scores_test, r2_scores_train, num_feats, results = [], [], [], dict()\n",
    "    for cutoff in cutoffs:\n",
    "\n",
    "        #reduce X matrix\n",
    "        reduce_X = X.iloc[:, np.where((X.sum() > cutoff) == True)[0]]\n",
    "        num_feats.append(reduce_X.shape[1])\n",
    "\n",
    "        #split the data into train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size = test_size, random_state=random_state)\n",
    "\n",
    "        #fit the model and obtain pred response\n",
    "        lm_model = LinearRegression(normalize=True)\n",
    "        lm_model.fit(X_train, y_train)\n",
    "        y_test_preds = lm_model.predict(X_test)\n",
    "        y_train_preds = lm_model.predict(X_train)\n",
    "\n",
    "        #append the r2 value from the test set\n",
    "        r2_scores_test.append(r2_score(y_test, y_test_preds))\n",
    "        r2_scores_train.append(r2_score(y_train, y_train_preds))\n",
    "        results[str(cutoff)] = r2_score(y_test, y_test_preds)\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(num_feats, r2_scores_test, label=\"Test\", alpha=.5)\n",
    "        plt.plot(num_feats, r2_scores_train, label=\"Train\", alpha=.5)\n",
    "        plt.xlabel('Number of Features')\n",
    "        plt.ylabel('Rsquared')\n",
    "        plt.title('Rsquared by Number of Features')\n",
    "        plt.legend(loc=1)\n",
    "        plt.show()\n",
    "\n",
    "    best_cutoff = max(results, key=results.get)\n",
    "\n",
    "    #reduce X matrix\n",
    "    reduce_X = X.iloc[:, np.where((X.sum() > int(best_cutoff)) == True)[0]]\n",
    "    num_feats.append(reduce_X.shape[1])\n",
    "\n",
    "    #split the data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size = test_size, random_state=random_state)\n",
    "\n",
    "    #fit the model\n",
    "    lm_model = LinearRegression(normalize=True)\n",
    "    lm_model.fit(X_train, y_train)\n",
    "\n",
    "    return r2_scores_test, r2_scores_train, lm_model, X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4721753984716849, 0.4721753984716849, 0.4721753984716849, 0.6098080796737866, 0.7277635120396052, 0.7277635120396052, 0.7277635120396052, 0.7277635120396052, 0.7277635120396052, 0.7277635120396052] [0.6153966063077794, 0.6153966063077794, 0.6153966063077794, 0.6463441282507583, 0.7465176531369253, 0.7465176531369253, 0.7465176531369253, 0.7465176531369253, 0.7465176531369253, 0.7465176531369253] LinearRegression(normalize=True)      Economy (GDP per Capita)    Family  Health (Life Expectancy)   Freedom  \\\n",
      "108                  9.403371  0.852532                 56.506012  0.759330   \n",
      "90                   8.350645  0.728601                 57.203987  0.794797   \n",
      "104                  9.417931  0.671070                 68.708138  0.781994   \n",
      "16                  10.732819  0.898874                 72.202019  0.867371   \n",
      "111                  7.468545  0.712944                 53.889454  0.665564   \n",
      "..                        ...       ...                       ...       ...   \n",
      "71                   9.751861  0.855315                 68.505348  0.649566   \n",
      "106                  8.287064  0.687293                 64.503067  0.900625   \n",
      "14                   9.658156  0.901546                 71.299850  0.934739   \n",
      "92                  10.129419  0.826314                 66.902817  0.608830   \n",
      "102                  6.842167  0.617435                 53.500095  0.759772   \n",
      "\n",
      "     Trust (Government Corruption)  \n",
      "108                       0.843424  \n",
      "90                        0.847965  \n",
      "104                       0.896304  \n",
      "16                        0.456422  \n",
      "111                       0.739795  \n",
      "..                             ...  \n",
      "71                        0.783122  \n",
      "106                       0.661844  \n",
      "14                        0.786332  \n",
      "92                        0.748197  \n",
      "102                       0.722530  \n",
      "\n",
      "[107 rows x 5 columns]      Economy (GDP per Capita)    Family  Health (Life Expectancy)   Freedom  \\\n",
      "84                   8.225561  0.658049                 49.503773  0.727909   \n",
      "86                   9.518633  0.913161                 70.599998  0.853963   \n",
      "97                   8.118648  0.700386                 52.704941  0.763052   \n",
      "115                  9.100476  0.757479                 66.750656  0.712018   \n",
      "29                  10.481836  0.889879                 73.601685  0.664652   \n",
      "114                  8.576625  0.737217                 49.861908  0.759578   \n",
      "78                  10.070875  0.874624                 70.214905  0.714839   \n",
      "81                  10.262519  0.816509                 67.102158  0.894627   \n",
      "18                  10.404163  0.914431                 70.047935  0.818537   \n",
      "15                  11.160978  0.942082                 72.300789  0.886983   \n",
      "19                  10.673639  0.911633                 72.001648  0.813582   \n",
      "12                  10.600135  0.936683                 72.301605  0.834744   \n",
      "9                   11.450681  0.906912                 72.599998  0.905636   \n",
      "42                  10.265124  0.874257                 69.311134  0.862056   \n",
      "51                   8.993546  0.846730                 61.926762  0.915463   \n",
      "69                   8.776714  0.843314                 65.013016  0.721609   \n",
      "109                  9.661096  0.747695                 59.903549  0.633183   \n",
      "136                  7.281686  0.668196                 59.105427  0.557574   \n",
      "65                   8.482727  0.689062                 58.253136  0.734834   \n",
      "96                   8.940313  0.592628                 65.896240  0.772072   \n",
      "75                  10.405703  0.820357                 73.702225  0.795294   \n",
      "123                  7.054380  0.709281                 56.096313  0.735269   \n",
      "31                   9.566435  0.896724                 66.480164  0.799805   \n",
      "66                   9.389982  0.898728                 65.639938  0.885923   \n",
      "55                   8.424535  0.821870                 67.198769  0.870603   \n",
      "30                  11.395521  0.910269                 76.804581  0.926645   \n",
      "26                  10.797812  0.874067                 66.305145  0.854191   \n",
      "131                  9.162674  0.770290                 51.188236  0.646822   \n",
      "135                  7.509386  0.743307                 58.639591  0.740795   \n",
      "36                  10.347750  0.922494                 68.906342  0.749953   \n",
      "113                  7.629852  0.731469                 51.726982  0.711566   \n",
      "94                   9.748033  0.958966                 62.211708  0.826457   \n",
      "68                   9.455817  0.829204                 67.808136  0.651353   \n",
      "22                  10.584223  0.937104                 73.801933  0.825468   \n",
      "45                   8.493160  0.857497                 67.507179  0.863903   \n",
      "76                  10.132326  0.814380                 72.405258  0.541345   \n",
      "11                  10.720596  0.944855                 73.604538  0.915432   \n",
      "134                  7.357711  0.551313                 54.719898  0.649829   \n",
      "132                  8.680482  0.784407                 58.961712  0.895075   \n",
      "128                  8.233919  0.790819                 57.010178  0.551523   \n",
      "27                  10.462927  0.921125                 74.402710  0.751990   \n",
      "64                   8.851115  0.803109                 63.600471  0.875873   \n",
      "142                  7.960488  0.780496                 48.003624  0.738126   \n",
      "127                  9.314973  0.688719                 66.897858  0.593362   \n",
      "4                   11.087804  0.952487                 73.200783  0.955750   \n",
      "32                  10.392323  0.939576                 71.102989  0.936143   \n",
      "\n",
      "     Trust (Government Corruption)  \n",
      "84                        0.790772  \n",
      "86                        0.824211  \n",
      "97                        0.851337  \n",
      "115                       0.773545  \n",
      "29                        0.873405  \n",
      "114                       0.861874  \n",
      "78                        0.916495  \n",
      "81                        0.839302  \n",
      "18                        0.858446  \n",
      "15                        0.357184  \n",
      "19                        0.612298  \n",
      "12                        0.435916  \n",
      "9                         0.367084  \n",
      "42                        0.686927  \n",
      "51                        0.733634  \n",
      "69                        0.913314  \n",
      "109                       0.822262  \n",
      "136                       0.817486  \n",
      "65                        0.745705  \n",
      "96                        0.815725  \n",
      "75                        0.626116  \n",
      "123                       0.856376  \n",
      "31                        0.770601  \n",
      "66                        0.834789  \n",
      "55                        0.801132  \n",
      "30                        0.109784  \n",
      "26                        0.682620  \n",
      "131                       0.708263  \n",
      "135                       0.753690  \n",
      "36                        0.918096  \n",
      "113                       0.839328  \n",
      "94                        0.883692  \n",
      "68                        0.933769  \n",
      "22                        0.583521  \n",
      "45                        0.665950  \n",
      "76                        0.859931  \n",
      "11                        0.415169  \n",
      "134                       0.757733  \n",
      "132                       0.645124  \n",
      "128                       0.746224  \n",
      "27                        0.765860  \n",
      "64                        0.822606  \n",
      "142                       0.857392  \n",
      "127                       0.867590  \n",
      "4                         0.263218  \n",
      "32                        0.817071   108    4.8141\n",
      "90     5.1480\n",
      "104    4.8827\n",
      "16     7.0758\n",
      "111    4.7687\n",
      "        ...  \n",
      "71     5.5461\n",
      "106    4.8328\n",
      "14     7.1214\n",
      "92     5.1318\n",
      "102    4.9096\n",
      "Name: Happiness Score, Length: 107, dtype: float64 84     5.2333\n",
      "86     5.1976\n",
      "97     5.0849\n",
      "115    4.6768\n",
      "29     6.3874\n",
      "114    4.7241\n",
      "78     5.5047\n",
      "81     5.3843\n",
      "18     6.9109\n",
      "15     7.0937\n",
      "19     6.8635\n",
      "12     7.1645\n",
      "9      7.2375\n",
      "42     6.1863\n",
      "51     6.0060\n",
      "69     5.6075\n",
      "109    4.7848\n",
      "136    4.1656\n",
      "65     5.6933\n",
      "96     5.0948\n",
      "75     5.5355\n",
      "123    4.5579\n",
      "31     6.3756\n",
      "66     5.6921\n",
      "55     5.9532\n",
      "30     6.3771\n",
      "26     6.4065\n",
      "131    4.3081\n",
      "135    4.1862\n",
      "36     6.2806\n",
      "113    4.7293\n",
      "94     5.1191\n",
      "68     5.6741\n",
      "22     6.6638\n",
      "45     6.1371\n",
      "76     5.5150\n",
      "11     7.2228\n",
      "134    4.1872\n",
      "132    4.3080\n",
      "128    4.3746\n",
      "27     6.4009\n",
      "64     5.7475\n",
      "142    3.6528\n",
      "127    4.3922\n",
      "4      7.4880\n",
      "32     6.3634\n",
      "Name: Happiness Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y=df_2020['Happiness Score']\n",
    "X=df_2020[['Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)','Freedom', 'Generosity',\n",
    "           'Trust (Government Corruption)']]\n",
    "cutoffs = [5000, 3500, 2500, 1000, 100, 50, 30, 20, 10, 5]\n",
    "r2_scores_test, r2_scores_train, lm_model, X_train, X_test, y_train, y_test = find_optimal_lm_mod(X, y, cutoffs)\n",
    "print(r2_scores_test, r2_scores_train, lm_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion** - Linear Regression has low mean squared error for both train(76%) and test(59%) still the performance can be improved with the usage of other Algorithms\n",
    "\n",
    "Here Categorical Variable in this Dataset is Region. If we try to split this the Accuracy can be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4721753984716849,\n",
       " 0.4721753984716849,\n",
       " 0.4721753984716849,\n",
       " 0.6098080796737866,\n",
       " 0.7277635120396058,\n",
       " 0.7277635120396058,\n",
       " 0.7277635120396058,\n",
       " 0.7277635120396058,\n",
       " 0.7277635120396058,\n",
       " 0.7277635120396058]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_scores_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = df_2020.select_dtypes(include=['object']) # Subset to a dataframe only holding the categorical columns\n",
    "cat_df = cat_df[['Regional indicator']]\n",
    "#Pull a list of the column names of the categorical variables\n",
    "cat_cols_lst = cat_df.columns\n",
    "\n",
    "def create_dummy_df(df, cat_cols, dummy_na):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with categorical variables you want to dummy\n",
    "    cat_cols - list of strings that are associated with names of the categorical columns\n",
    "    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not\n",
    "    \n",
    "    OUTPUT:\n",
    "    df - a new dataframe that has the following characteristics:\n",
    "            1. contains all columns that were not specified as categorical\n",
    "            2. removes all the original columns in cat_cols\n",
    "            3. dummy columns for each of the categorical columns in cat_cols\n",
    "            4. if dummy_na is True - it also contains dummy columns for the NaN values\n",
    "            5. Use a prefix of the column name with an underscore (_) for separating \n",
    "    '''\n",
    "    for col in  cat_cols:\n",
    "        try:\n",
    "            # for each cat add dummy var, drop original column\n",
    "            df = pd.concat([df.drop(col, axis=1), pd.get_dummies(df[col], prefix=col, prefix_sep='_', drop_first=True, dummy_na=dummy_na)], axis=1)\n",
    "        except:\n",
    "            continue\n",
    "    return df\n",
    "\n",
    "df_new=create_dummy_df(df_2020,cat_cols_lst,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'Happiness Score', 'Standard error of ladder score',\n",
       "       'upperwhisker', 'lowerwhisker', 'Economy (GDP per Capita)', 'Family',\n",
       "       'Health (Life Expectancy)', 'Freedom', 'Generosity',\n",
       "       'Trust (Government Corruption)', 'Ladder score in Dystopia',\n",
       "       'Explained by: Log GDP per capita', 'Explained by: Social support',\n",
       "       'Explained by: Healthy life expectancy',\n",
       "       'Explained by: Freedom to make life choices',\n",
       "       'Explained by: Generosity', 'Explained by: Perceptions of corruption',\n",
       "       'Dystopia + residual', 'Happiness Rank', 'Year',\n",
       "       'Regional indicator_Commonwealth of Independent States',\n",
       "       'Regional indicator_East Asia',\n",
       "       'Regional indicator_Latin America and Caribbean',\n",
       "       'Regional indicator_Middle East and North Africa',\n",
       "       'Regional indicator_North America and ANZ',\n",
       "       'Regional indicator_South Asia', 'Regional indicator_Southeast Asia',\n",
       "       'Regional indicator_Sub-Saharan Africa',\n",
       "       'Regional indicator_Western Europe'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fit_linear_mod(df, response_col, cat_cols, dummy_na, test_size=.3, rand_state=42):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - a dataframe holding all the variables of interest\n",
    "    response_col - a string holding the name of the column \n",
    "    cat_cols - list of strings that are associated with names of the categorical columns\n",
    "    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not\n",
    "    test_size - a float between [0,1] about what proportion of data should be in the test dataset\n",
    "    rand_state - an int that is provided as the random state for splitting the data into training and test \n",
    "    \n",
    "    OUTPUT:\n",
    "    test_score - float - r2 score on the test data\n",
    "    train_score - float - r2 score on the test data\n",
    "    lm_model - model object from sklearn\n",
    "    X_train, X_test, y_train, y_test - output from sklearn train test split used for optimal model\n",
    "    \n",
    "    Your function should:\n",
    "    1. Drop the rows with missing response values\n",
    "    2. Drop columns with NaN for all the values\n",
    "    3. Use create_dummy_df to dummy categorical columns\n",
    "    4. Fill the mean of the column for any missing values \n",
    "    5. Split your data into an X matrix and a response vector y\n",
    "    6. Create training and test sets of data\n",
    "    7. Instantiate a LinearRegression model with normalized data\n",
    "    8. Fit your model to the training data\n",
    "    9. Predict the response for the training data and the test data\n",
    "    10. Obtain an rsquared value for both the training and test data\n",
    "    '''\n",
    "    #Drop the rows with missing response values\n",
    "    df  = df.dropna(subset=[response_col], axis=0)\n",
    "\n",
    "    #Drop columns with all NaN values\n",
    "    df = df.dropna(how='all', axis=1)\n",
    "\n",
    "    #Dummy categorical variables\n",
    "    df = create_dummy_df(df, cat_cols, dummy_na)\n",
    "\n",
    "#     # Mean function\n",
    "#     fill_mean = lambda col: col.fillna(col.mean())\n",
    "#     # Fill the mean\n",
    "#     df = df.apply(fill_mean, axis=0)\n",
    "\n",
    "    #Split into explanatory and response variables\n",
    "    X = df.drop([response_col,'Country'], axis=1)\n",
    "    y = df[response_col]\n",
    "\n",
    "    #Split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=rand_state)\n",
    "\n",
    "    lm_model = LinearRegression(normalize=True) # Instantiate\n",
    "    lm_model.fit(X_train, y_train) #Fit\n",
    "\n",
    "    #Predict using your model\n",
    "    y_test_preds = lm_model.predict(X_test)\n",
    "    y_train_preds = lm_model.predict(X_train)\n",
    "\n",
    "    #Score using your model\n",
    "    test_score = r2_score(y_test, y_test_preds)\n",
    "    train_score = r2_score(y_train, y_train_preds)\n",
    "\n",
    "    return test_score, train_score, lm_model, X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "#Test your function with the above dataset\n",
    "test_score, train_score, lm_model, X_train, X_test, y_train, y_test = clean_fit_linear_mod(df_new, 'Happiness Score', cat_cols_lst, dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The rsquared on the test data was 0.9999999999999999.\n"
     ]
    }
   ],
   "source": [
    "#Print training and testing score\n",
    "print(\" The rsquared on the test data was {}.\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
